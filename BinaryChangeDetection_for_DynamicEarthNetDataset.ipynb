{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedericoMiscione/LabIA_Prjct/blob/master/BinaryChangeDetection_for_DynamicEarthNetDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-80e5qU0-bni",
        "outputId": "dca8896a-034e-48a7-a86e-f0ce0a093711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.3.9)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.11.17)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm import tqdm\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "!pip install rasterio\n",
        "import rasterio\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, jaccard_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfuYom-JaZon"
      },
      "source": [
        "Connessione al drive da cui prendere il dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYli9aJTaExa",
        "outputId": "4a1eb8bd-a2d0-4396-9ba7-5ceb37ab4746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyEPgXv1KPxB",
        "outputId": "46d9c301-73b7-41fc-e369-5666f131dd19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version:  2.1.0+cu121  Device:  cpu\n"
          ]
        }
      ],
      "source": [
        "# Check del device disponibile [GPU --> \"cuda\" || CPU --> \"cpu\"]\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Using PyTorch version: \", torch.__version__, \" Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMCUXfe3axvu"
      },
      "source": [
        "Definizione dei path e dei filename da cui prendere il dataset e suddividerlo in train, validation  e test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4Ah8nwQRaS1S"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/content/gdrive/My Drive/Dataset_progetto\"\n",
        "train_txt = \"train.txt\"\n",
        "val_txt = \"val.txt\"\n",
        "test_txt = \"test.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6pGzWyGua1B"
      },
      "source": [
        "Implementazione della classe dataset con le opportune modifiche effettuate basandosi sulle osservazioni riguardanti il dataset specifico Dynamic Earth Net"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A"
      ],
      "metadata": {
        "id": "aV8BXsPLwf5x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jNi_IBNlt530"
      },
      "outputs": [],
      "source": [
        "class DynamicEarthNetDataset(Dataset):\n",
        "\n",
        "  def __init__(self, root, mode, period, transform, num_classes=7, ignored_classes=[1, 2, 3, 4, 5, 6]):\n",
        "    super().__init__()\n",
        "\n",
        "    # Path da cui caricare gli elementi del dataset\n",
        "    self.root = root\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "    # mode: \"train\" or \"val\" or \"test\"\n",
        "    # Utile per la suddivisione del dataset in train_set, validation_set e test_set\n",
        "    self.train = False\n",
        "    if mode == \"train\":\n",
        "      self.txt_file = train_txt\n",
        "      self.train = True\n",
        "    elif mode == \"val\":\n",
        "      self.txt_file = val_txt\n",
        "      self.train = False\n",
        "    elif mode == \"test\":\n",
        "      self.txt_file = test_txt\n",
        "      self.train = False\n",
        "\n",
        "    # period: \"biannual\" or \"annual\" | \"biannual\": semestrale => self.period = 6 ; \"annual\": annuale => self.period = 12\n",
        "    #                                | di default si sceglie di confrontarla con lo snapshot più recente in ordine temporale (self.period = 22)\n",
        "    # Utile per selezionare il periodo temporale di confronto tra due immagini della stessa area geografica\n",
        "    # Ogni considerazione è fatta tenendo conto del numero di mesi a disposizione nel dataset [Osservazioni di 2 anni => 24 mesi]\n",
        "    if period == \"biannual\":\n",
        "      self.period = 6\n",
        "    elif period == \"annual\":\n",
        "      self.period = 12\n",
        "    else:\n",
        "      self.period = 22\n",
        "\n",
        "    self.num_classes = num_classes\n",
        "    self.ignored_classes = ignored_classes\n",
        "\n",
        "    # transform function da applicare alle immagini del dataset\n",
        "    self.transform = transform\n",
        "\n",
        "    aug_transform_with_label = []\n",
        "\n",
        "    if self.train == True:\n",
        "      aug_transform_with_label = [\n",
        "          A.VerticalFlip(p=0.5),\n",
        "          A.HorizontalFlip(p=0.5),\n",
        "          A.Resize(height=384, width=384, always_apply=True),\n",
        "          A.RandomCrop(height=256, width=256, always_apply=True, p=1.0)\n",
        "      ]\n",
        "    elif self.train == False:\n",
        "      aug_transform_with_label = [\n",
        "          A.Resize(height=256, width=256, always_apply=True)\n",
        "      ]\n",
        "\n",
        "    self.dual_transform_l = A.Compose(aug_transform_with_label, p=1.0, additional_targets={'image2': 'image', 'mask' : 'mask'}, is_check_shapes=False)\n",
        "\n",
        "    # liste delle immagini e delle relative mask\n",
        "    self.imgs_list, self.masks_list = self.FilesLoader(self.txt_file)\n",
        "\n",
        "  # Metodo utile per caricamento dei file dal dataset\n",
        "  def FilesLoader(self, txt_file):\n",
        "    with open(os.path.join(self.root, txt_file), 'r') as f:\n",
        "      files_list = f.read().splitlines()\n",
        "\n",
        "    imgs_list = []\n",
        "    masks_list = []\n",
        "    for idx in range(len(files_list)):\n",
        "      img_path, mask_path = files_list[idx].split()\n",
        "      imgs_list.append(img_path)\n",
        "      masks_list.append(mask_path)\n",
        "\n",
        "    del files_list\n",
        "    return imgs_list, masks_list\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs_list)\n",
        "\n",
        "  def mean_n_std_calculator(self):\n",
        "    mean = np.zeros((4,))\n",
        "    std = np.zeros((4,))\n",
        "\n",
        "    for filename in self.imgs_list:\n",
        "      img = rasterio.open(os.path.join(self.root, filename)).read()\n",
        "      img = img.astype(np.float32)\n",
        "      mean += np.mean(img, axis=(1, 2))\n",
        "      std += np.std(img, axis=(1, 2))\n",
        "\n",
        "    mean /= len(self.imgs_list)\n",
        "    std /= len(self.imgs_list)\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "  def get_mask(self, label):\n",
        "    mask = np.zeros((label.shape[1], label.shape[2]), dtype=np.int64)\n",
        "\n",
        "    for i in range(self.num_classes):\n",
        "      if i in self.ignored_classes:\n",
        "        mask[label[i,:,:] == 255] = -1\n",
        "      else:\n",
        "        mask[label[i,:,:] == 255] = i\n",
        "\n",
        "    return mask\n",
        "\n",
        "  # Elementi della label tutti 0-1 (if pixel == -1 => pixel = 1)\n",
        "  def label_mod(self, label):\n",
        "    for i in range(label.shape[0]):\n",
        "      for j in range(label.shape[1]):\n",
        "        if label[i, j] != 0:\n",
        "          label[i, j] = 1\n",
        "        else:\n",
        "          label[i, j] = 0\n",
        "\n",
        "    return label\n",
        "\n",
        "  def create_label(self, label):\n",
        "    res = np.zeros((2, label.shape[-2], label.shape[-1]), dtype=np.float32)\n",
        "\n",
        "    for i in range(label.shape[-2]):\n",
        "      for j in range(label.shape[-1]):\n",
        "\n",
        "        if label[i, j] == 0: # Ch = 0 [No_Change]\n",
        "          res[0, i, j] = 1\n",
        "        else:                # Ch = 1 [Change]\n",
        "          res[1, i, j] = 1\n",
        "\n",
        "    return res\n",
        "\n",
        "  def get_img_place_and_date(self, img_path):\n",
        "    token_list = img_path.split(\"/\")\n",
        "    place, date = token_list[-2], token_list[-1]\n",
        "    if date.endswith(\".tif\"):\n",
        "      date = date.removesuffix(\".tif\")\n",
        "    del token_list\n",
        "    return place, date\n",
        "\n",
        "  def get_year_month(self, date, is_mask=False):\n",
        "    if is_mask:\n",
        "      year = date.split(\"_\")[0]\n",
        "      month = date.split(\"_\")[1]\n",
        "    else:\n",
        "      year = date.split(\"-\")[0]\n",
        "      month = date.split(\"-\")[1]\n",
        "    return year, month\n",
        "\n",
        "  def get_mask_place_and_date(self, mask_path):\n",
        "    token_list = mask_path.split(\"/\")\n",
        "    place, pos, date = token_list[-5], token_list[-2], token_list[-1]\n",
        "    if pos in date:\n",
        "      date = date.replace(pos, \"\")\n",
        "    if date.endswith(\".tif\"):\n",
        "      date = date.removesuffix(\".tif\")\n",
        "    del token_list, pos\n",
        "    return place, date\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    self.imgs_list = sorted(self.imgs_list)\n",
        "    self.masks_list = sorted(self.masks_list)\n",
        "\n",
        "    img = rasterio.open(os.path.join(self.root, self.imgs_list[index])).read()\n",
        "    label1 = rasterio.open(os.path.join(self.root, \"labels\", self.masks_list[index])).read()\n",
        "    mask1 = self.get_mask(label1)\n",
        "\n",
        "    # Acquisizione seconda immagine per confronto basata sul period settato\n",
        "    place, date = self.get_img_place_and_date(self.imgs_list[index])\n",
        "    year, month = self.get_year_month(date)\n",
        "\n",
        "    padding = 0\n",
        "    if year == \"2019\":\n",
        "       padding = 11\n",
        "\n",
        "    idx2 = padding + int(month) + self.period - 2\n",
        "\n",
        "    # Se si ha un immagine con cui confrontare in base al periodo scelto che supera la data 12/2019\n",
        "    # la si confronta con l'ultima immagine disponibile, ossia del mese di dicembre del 2019.\n",
        "    if idx2 > 22:\n",
        "      idx2 = -1\n",
        "    # Se l'immagine è del 12/2019 la si confronta con una che la precede di self.period mesi\n",
        "    if year == \"2019\" and month == \"12\":\n",
        "      idx2 = - self.period\n",
        "\n",
        "    sp_list = []\n",
        "    for i in range(len(self.imgs_list)):\n",
        "      if place in self.imgs_list[i] and date not in self.imgs_list[i]:\n",
        "        sp_list.append(self.imgs_list[i])\n",
        "\n",
        "    sp_list = sorted(sp_list)\n",
        "    # idx2 = np.random.randint(0, 22)\n",
        "    img2 = rasterio.open(os.path.join(self.root, sp_list[idx2])).read()\n",
        "    _, date2 = self.get_img_place_and_date(sp_list[idx2])\n",
        "    del sp_list\n",
        "\n",
        "    # Acquisizione relativa mask per genarazione della label\n",
        "    place, date_mask1 = self.get_mask_place_and_date(self.masks_list[index])\n",
        "    year, month = self.get_year_month(date_mask1)\n",
        "\n",
        "    sp_list = []\n",
        "    for i in range(len(self.masks_list)):\n",
        "      if place in self.masks_list[i] and date_mask1 not in self.masks_list[i]:\n",
        "        sp_list.append(self.masks_list[i])\n",
        "\n",
        "    sp_list = sorted(sp_list)\n",
        "    label2 = rasterio.open(os.path.join(self.root, \"labels\", sp_list[idx2])).read()\n",
        "    mask2 = self.get_mask(label2)\n",
        "    del sp_list\n",
        "\n",
        "    # Genesi della label finale\n",
        "    label = mask1 - mask2\n",
        "    label = self.label_mod(label)\n",
        "    # label = zoom(label, 0.375)\n",
        "    # label = self.create_label(label)\n",
        "\n",
        "    augmented_l = self.dual_transform_l(image=img.transpose(1, 2, 0).astype(np.float32), image2=img2.transpose(1, 2, 0).astype(np.float32), mask=label)\n",
        "    img = augmented_l['image'].transpose(2, 0, 1)\n",
        "    img2 = augmented_l['image2'].transpose(2, 0, 1)\n",
        "    label = augmented_l['mask']\n",
        "\n",
        "    img = torch.tensor(np.array(img), dtype=torch.float)\n",
        "    img2 = torch.tensor(np.array(img2), dtype=torch.float)\n",
        "    label = torch.tensor(np.array(label), dtype=torch.int)\n",
        "\n",
        "    if self.transform is not None:\n",
        "      img = self.transform(img)\n",
        "      img2 = self.transform(img2)\n",
        "\n",
        "    return img, img2, label # , date, date2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y1WjZrdqple"
      },
      "source": [
        "La media e la deviazione standard del train set sono state calcolate in un altro script per ogni banda delle immagini utilizzate nel train set, ossia 4 (RGB + Near-InfraRed) attraverso il metodo definito nella classe DENDataset\n",
        "\n",
        "```\n",
        "train_mean, train_std = train_set.mean_n_std_calculator()\n",
        "```\n",
        "Risultato:\n",
        "\n",
        "```\n",
        "Media train set: [ 666.90438769  903.53697729 1021.31235205 2610.93006829]\n",
        "\n",
        "Deviazione standard train set: [286.17857641 320.16555736 421.99044997 620.38192794]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XAbaLDX0p88b"
      },
      "outputs": [],
      "source": [
        "# Print the results\n",
        "# for i, (mean, std) in enumerate(zip(train_mean, train_std)):\n",
        "#     print(f\"Channel {i + 1}: Mean = {mean:.4f}, Std Deviation = {std:.4f}\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize((666.90438769, 903.53697729, 1021.31235205, 2610.93006829), (286.17857641, 320.16555736, 421.99044997, 620.38192794))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-fakAkwEb-b"
      },
      "source": [
        "Definizione del train, validation e test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td1mNR5KEbVX",
        "outputId": "895f5a10-f8f2-4091-c1e7-80bf1ad96556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_set size = 1080, valid_set size = 120, test_set size = 120\n"
          ]
        }
      ],
      "source": [
        "train_set = DynamicEarthNetDataset(DATA_PATH, \"train\", \"biannual\", transform=transform)\n",
        "valid_set = DynamicEarthNetDataset(DATA_PATH, \"val\", \"biannual\", transform=transform)\n",
        "test_set = DynamicEarthNetDataset(DATA_PATH, \"test\", \"biannual\", transform=transform)\n",
        "\n",
        "print(f\"train_set size = {len(train_set)}, valid_set size = {len(valid_set)}, test_set size = {len(test_set)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_KBgBxIGwMc"
      },
      "source": [
        "Definizione dei DataLoader del train, validation e test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZnH75iFnGvp2"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "num_threads = 2\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size, shuffle=True, num_workers=num_threads)\n",
        "valid_loader = DataLoader(valid_set, batch_size, shuffle=False, num_workers=num_threads)\n",
        "test_loader = DataLoader(test_set, batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1xTt21vEOR4"
      },
      "source": [
        "----------------------------------------------------------------------------------------------------\n",
        "### Visualizzazione delle immagini nel dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "inFp5RomdMzr"
      },
      "outputs": [],
      "source": [
        "def multispectral_to_rgb_visualization(img, lower_percentile=5, upper_percentile=95):\n",
        "    \"\"\"\n",
        "    Function for converting a multispectral image to RGB for visualization.\n",
        "    It clips the top and bottom 5% of the image intensities and then normalizes\n",
        "    the image to [0, 255] uint8 range.\n",
        "\n",
        "    Args:\n",
        "        img: a numpy array of shape (C, H, W) where the first 3 channels are BGR\n",
        "\n",
        "    Returns:\n",
        "        img: a numpy array of type uint8 and shape (H, W, 3) representing the RGB image\n",
        "    \"\"\"\n",
        "    assert isinstance(img, np.ndarray), \"The input image must be a numpy array\"\n",
        "\n",
        "    img = img.transpose(1,2,0)\n",
        "    img = img[:, :, [2, 1, 0]]\n",
        "    img = np.clip(img, np.percentile(img, lower_percentile), np.percentile(img, upper_percentile))\n",
        "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    return img\n",
        "\n",
        "def img_converter(img):\n",
        "  img = img.numpy()\n",
        "  img = multispectral_to_rgb_visualization(img)\n",
        "  return img\n",
        "\n",
        "def img_visualizer():\n",
        "  dataiter = iter(train_loader)\n",
        "  img1, img2, label = next(dataiter)\n",
        "  print(f\"{img1.shape}, {img2.shape}, {label.shape}\")\n",
        "\n",
        "  for batch in range(batch_size):\n",
        "\n",
        "    img_1 = img_converter(img1[batch])\n",
        "    img_2 = img_converter(img2[batch])\n",
        "    msk = label[batch].numpy()\n",
        "\n",
        "    imgs = [img_1, img_2, msk]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(9, 9))\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "      ax.imshow(imgs[i])\n",
        "      if i == 2:\n",
        "        ax.set_title(\"Label\")\n",
        "\n",
        "      ax.set_axis_off()\n",
        "\n",
        "    plt.show()\n",
        "    del imgs\n",
        "\n",
        "  del dataiter\n",
        "\n",
        "def img_x_segmentation_visualizer():\n",
        "  dataiter = iter(train_loader)\n",
        "  img, mask = next(dataiter)\n",
        "\n",
        "  imgs = []\n",
        "  for batch in range(1):\n",
        "    img_1 = img_converter(img[batch])\n",
        "    msk = mask[batch].numpy()\n",
        "\n",
        "    imgs = [img_1, msk]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 12))\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "      ax.imshow(imgs[i])\n",
        "      ax.set_axis_off()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  del imgs, dataiter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_visualizer()"
      ],
      "metadata": {
        "id": "57GwNuuZ3D4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXm2M5Ofbx86"
      },
      "outputs": [],
      "source": [
        "def label_visualizer():\n",
        "\n",
        "  for batch in valid_loader:\n",
        "    _, _, label = batch\n",
        "\n",
        "    _, axes = plt.subplots(1, batch_size, figsize=(6, 6))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "      labels = label[b]\n",
        "\n",
        "      for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(labels)\n",
        "      # ax.set_title(f\"{date1[i]}|{date2[i]}\")\n",
        "\n",
        "    plt.show()\n",
        "    del axes\n",
        "\n",
        "label_visualizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upApRwj5A0Hr"
      },
      "source": [
        "### Check sulla correttezza delle label\n",
        "Verifica che le labels siano delle change map composte da pixel di valore binario 0-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Toiqr8mR9yCa"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(train_loader)\n",
        "_, _, label = next(dataiter)\n",
        "\n",
        "for i in tqdm(range(batch_size)):\n",
        "  for h in range(label.shape[1]):\n",
        "    for w in range(label.shape[2]):\n",
        "      if label[i, h, w] != 0:\n",
        "        if label[i, h, w] != 1:\n",
        "          print(label[i, h, w])\n",
        "\n",
        "del dataiter, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyUNkYKy5bFd"
      },
      "source": [
        "## Calcolo dei weights\n",
        "\n",
        "Calcolo attraverso il seguente script che utilizza le label generate, che sono delle difference map, la percentuale dei changed pixel rispetto al totale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONfEO-Y85a2g"
      },
      "outputs": [],
      "source": [
        "def pixel_counter(label, total=0, changed=0):\n",
        "  for i in range(label.shape[0]):\n",
        "    for j in range(label.shape[1]):\n",
        "      total += 1\n",
        "      if label[i, j] != 0:\n",
        "        changed += 1\n",
        "  return total, changed\n",
        "\n",
        "def weights_calculator():\n",
        "    total_pixel, changed_pixel = 0, 0\n",
        "    update_list = []\n",
        "    for batch in tqdm(train_loader):\n",
        "      _, _, label = batch\n",
        "\n",
        "      for idx in range(batch_size):\n",
        "        total, changed = pixel_counter(label[idx])\n",
        "        total_pixel += total\n",
        "        changed_pixel += changed\n",
        "      change_ratio = changed_pixel / total_pixel\n",
        "      update_list.append(change_ratio)\n",
        "\n",
        "    change_ratio = changed_pixel / total_pixel\n",
        "    return total_pixel, changed_pixel, change_ratio, update_list\n",
        "\n",
        "total_pxl, changed_pxl, change_ratio, update_list = weights_calculator()\n",
        "print(f\"Pixel = {total_pxl}, Changed pixels = {changed_pxl} -> Change Ratio = {change_ratio}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmgvOP5H5dZt"
      },
      "source": [
        "Con il seguente risultato:\n",
        "```\n",
        "100%|██████████| 40/40 [3:48:37<00:00, 342.94s/it]\n",
        "Pixel = 1132462080, Changed pixels = 6032254 -> Change Ratio = 0.005326671953554507\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gi8_AfdO5OM"
      },
      "source": [
        "----------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk6dW5rdkxmU"
      },
      "outputs": [],
      "source": [
        "biannual_percent = (cnt_change_b/cnt_biannual)*100\n",
        "annual_percent = (cnt_change_a/cnt_annual)*100\n",
        "\n",
        "print(f\"Biannual: {biannual_percent:.2f}%\")\n",
        "print(f\"Annual:   {annual_percent:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuVs-9o85062"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Biannual: 77.59%\n",
        "Annual:   75.46%\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JhAHm9bL49Y"
      },
      "outputs": [],
      "source": [
        "# Definizione del blocco convoluzionale\n",
        "class Conv_Block(nn.Module):\n",
        "  def __init__(self, input_ch, output_ch):\n",
        "    super(Conv_Block, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(input_ch, output_ch, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(output_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(output_ch, output_ch, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(output_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "class dwn_sampler(nn.Module):\n",
        "  def __init__(self, input_ch, output_ch):\n",
        "    super(dwn_sampler, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.MaxPool2d(2),\n",
        "        Conv_Block(input_ch, output_ch)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "class up_sampler(nn.Module):\n",
        "  def __init__(self, input_ch, output_ch):\n",
        "    super(up_sampler, self).__init__()\n",
        "    self.up_sampler = nn.ConvTranspose2d(input_ch // 2, input_ch // 2, kernel_size=2, stride=2, bias=False)\n",
        "    self.conv = Conv_Block(input_ch, output_ch)\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    x1 = self.up_sampler(x1)\n",
        "\n",
        "    width = x2.size()[2] - x1.size()[2]\n",
        "    height = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "    x1 = F.pad(x1, (width // 2, width - (width // 2), height // 2, height - (height // 2)))\n",
        "    x = torch.cat([x2, x1], dim=1)\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "class last_conv(nn.Module):\n",
        "  def __init__(self, input_ch, output_ch):\n",
        "    super(last_conv, self).__init__()\n",
        "    self.conv = nn.Conv2d(input_ch, output_ch, 1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    return x\n",
        "\n",
        "class DEN_Unet(nn.Module):\n",
        "  def __init__(self, input_ch=8, output_ch=1):\n",
        "    super(DEN_Unet, self).__init__()\n",
        "\n",
        "    self.conv = Conv_Block(input_ch, 32)\n",
        "\n",
        "    self.down_1 = dwn_sampler(32, 64)\n",
        "    self.down_2 = dwn_sampler(64, 128)\n",
        "    self.down_3 = dwn_sampler(128, 256)\n",
        "    self.down_4 = dwn_sampler(256, 256)\n",
        "\n",
        "    self.up_1 = up_sampler(512, 128)\n",
        "    self.up_2 = up_sampler(256, 64)\n",
        "    self.up_3 = up_sampler(128, 32)\n",
        "    self.up_4 = up_sampler(64, 32)\n",
        "\n",
        "    self.last_conv = last_conv(32, output_ch)\n",
        "\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    x = torch.cat((x1, x2), dim=1)\n",
        "\n",
        "    x1 = self.conv(x)\n",
        "\n",
        "    # Downsampling\n",
        "    x2 = self.down_1(x1)\n",
        "    x3 = self.down_2(x2)\n",
        "    x4 = self.down_3(x3)\n",
        "    x5 = self.down_4(x4)\n",
        "\n",
        "    # Upsampling\n",
        "    x = self.up_1(x5, x4)\n",
        "    x = self.up_2(x, x3)\n",
        "    x = self.up_3(x, x2)\n",
        "    x = self.up_4(x, x1)\n",
        "\n",
        "    x = self.last_conv(x)\n",
        "    return self.activation(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtrQ3XYlLvkO"
      },
      "source": [
        "-------------------------------------------------------------------------------------\n",
        "#Definizione del modello di Rete Neurale"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConvBlock(nn.Module):\n",
        "  def __init__(self, in_ch, out_ch):\n",
        "    super(DoubleConvBlock, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(out_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(out_ch),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)\n",
        "\n",
        "class U_Net(nn.Module):\n",
        "  def __init__(self, in_ch=8, out_ch=2, layers=[32, 64, 128, 256]):\n",
        "    super(U_Net, self).__init__()\n",
        "    self.decoders = nn.ModuleList()\n",
        "    self.encoders = nn.ModuleList()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    for layer in layers:\n",
        "      self.encoders.append(DoubleConvBlock(in_ch, layer))\n",
        "      in_ch = layer\n",
        "\n",
        "    for layer in reversed(layers):\n",
        "      self.decoders.append(nn.ConvTranspose2d(layer*2, layer, kernel_size=2, stride=2))\n",
        "      self.decoders.append(DoubleConvBlock(layer*2, layer))\n",
        "\n",
        "    self.bottleneck = DoubleConvBlock(layers[-1], layers[-1]*2)\n",
        "    self.final_conv = nn.Conv2d(layers[0], out_ch, kernel_size=1)\n",
        "\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    skip_connections = []\n",
        "\n",
        "    x = torch.cat((x1, x2), dim=1)\n",
        "\n",
        "    for encoder in self.encoders:\n",
        "      x = encoder(x)\n",
        "      skip_connections.append(x)\n",
        "      x = self.pool(x)\n",
        "\n",
        "    x = self.bottleneck(x)\n",
        "\n",
        "    skip_connections = skip_connections[::-1]\n",
        "\n",
        "    for index in range(0, len(self.decoders), 2):\n",
        "      x = self.decoders[index](x)\n",
        "      skip_connection =  skip_connections[index//2]\n",
        "      concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "      x = self.decoders[index+1](concat_skip)\n",
        "    x = self.final_conv(x)\n",
        "    return x # self.activation(x)"
      ],
      "metadata": {
        "id": "UV1igiFbKnYs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FC_Siam_Conc(nn.Module):\n",
        "  def __init__(self, in_ch=4, out_ch=2):\n",
        "    super(FC_Siam_Conc, self).__init__()\n",
        "\n",
        "    self.first_conv = nn.Sequential(\n",
        "        nn.Conv2d(in_ch, 16, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    self.cb_1 = nn.Sequential(\n",
        "        nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.cb_2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.cb_3 = nn.Sequential(\n",
        "        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.tcb_1 = nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "\n",
        "    self.tcb_2 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(384, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.2)\n",
        "      )\n",
        "\n",
        "    self.tcb_3 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(192, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(32, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.tcb_4 = nn.Sequential(\n",
        "        nn.ConvTranspose2d(96, 32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.final_tcb = nn.Sequential(\n",
        "        nn.ConvTranspose2d(48, 16, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.ConvTranspose2d(16, out_ch, kernel_size=3, stride=1, padding=1),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.activation = nn.Sigmoid()\n",
        "\n",
        "  def single_branch(self, x):\n",
        "    x1 = self.first_conv(x)\n",
        "    x2 = self.cb_1(self.pool(x1))\n",
        "    x3 = self.cb_2(self.pool(x2))\n",
        "    x4 = self.cb_3(self.pool(x3))\n",
        "    return x1, x2, x3, x4\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    x1, x2, x3, x4 = self.single_branch(x)\n",
        "    y1, y2, y3, y4 = self.single_branch(y)\n",
        "\n",
        "    out = self.pool(y4)\n",
        "    out = self.tcb_1(out)\n",
        "\n",
        "    out = torch.cat((out, y4, x4), dim=1)\n",
        "    out = self.tcb_2(out)\n",
        "\n",
        "    out = torch.cat((out, y3, x3), dim=1)\n",
        "    out = self.tcb_3(out)\n",
        "\n",
        "    out = torch.cat((out, y2, x2), dim=1)\n",
        "    out = self.tcb_4(out)\n",
        "\n",
        "    out = torch.cat((out, y1, x1), dim=1)\n",
        "    out = self.final_tcb(out)\n",
        "\n",
        "    return out # self.activation(out)"
      ],
      "metadata": {
        "id": "uDzV0PIieMvq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3tajZF4oKdUn"
      },
      "outputs": [],
      "source": [
        "tot_pixel = 1132462080\n",
        "changed = 6032254\n",
        "not_changed = tot_pixel - changed\n",
        "\n",
        "w_ch = not_changed / tot_pixel\n",
        "w_nch = changed / tot_pixel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zpOU88e632DC"
      },
      "outputs": [],
      "source": [
        "# model = U_Net().to(device)\n",
        "model = FC_Siam_Conc().to(device)\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOZJN8jy4gUq",
        "outputId": "89239ef4-274d-47b6-ab29-0943c72f4bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parametri addestrabili: 1546354\n"
          ]
        }
      ],
      "source": [
        "# Calcolo del numero di parametri da addestrare nel modello\n",
        "params = 0\n",
        "for param in model.parameters():\n",
        "  if param.requires_grad:\n",
        "    params += param.numel()\n",
        "\n",
        "print(f\"Parametri addestrabili: {params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KhQpPvRt4m8R"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.1)\n",
        "pos_weight = torch.tensor([2*w_nch , 2*w_ch]).unsqueeze(dim=1).unsqueeze(dim=2)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "btAtvV3LRP7e"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "    all_labels, all_preds = [], []\n",
        "\n",
        "    for img1, img2, label in tqdm(train_loader):\n",
        "        img1, img2, label = img1.to(device=device, dtype=torch.float32), img2.to(device=device, dtype=torch.float32), label.unsqueeze(dim=1).to(device, dtype=torch.float32) # label.to(device=device, dtype=torch.float32)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(img1, img2)\n",
        "        loss = criterion(output, label.expand_as(output))\n",
        "\n",
        "        _, preds = torch.max(output, dim=1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        all_labels = np.concatenate((all_labels, label.flatten().cpu().int()))\n",
        "        all_preds = np.concatenate((all_preds, preds.flatten().cpu().int()))\n",
        "\n",
        "        del img1, img2, label\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "    train_acc = accuracy_score(all_labels, all_preds)\n",
        "    mean_loss = np.array(epoch_loss).mean()\n",
        "    # Return average training loss for the epoch\n",
        "    return mean_loss, train_acc\n",
        "\n",
        "def validate():\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    epoch_loss = []\n",
        "    tp, tn, fp, fn = 0, 0, 0, 0\n",
        "    val_loss, correct = 0, 0\n",
        "    n_elem = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for img1, img2, label in tqdm(valid_loader):\n",
        "        img1, img2, label = img1.to(device=device, dtype=torch.float32), img2.to(device=device, dtype=torch.float32), label.unsqueeze(dim=1).to(device=device, dtype=torch.float32)\n",
        "\n",
        "        output = model(img1, img2)\n",
        "\n",
        "        epoch_loss.append(criterion(output, label.expand_as(output)).item())\n",
        "\n",
        "        _, preds = torch.max(output, dim=1)\n",
        "\n",
        "        axes = None\n",
        "        for batch in range(batch_size):\n",
        "          _, axes = plt.subplots(1, 4, figsize=(16, 16))\n",
        "          n_elem += 1\n",
        "          for i, ax in enumerate(axes.flat):\n",
        "            # if i in [0, 1, 4, 5, 8, 9, 12, 13]: # , 16, 17, 20, 21, 24, 25, 28, 29]:\n",
        "            if i == 0:\n",
        "              ax.imshow(img_converter(img1[batch].cpu()))\n",
        "              ax.set_title(\"Before\")\n",
        "              ax.set_axis_off()\n",
        "            elif i == 1:\n",
        "              ax.imshow(img_converter(img2[batch].cpu()))\n",
        "              ax.set_title(\"Then\")\n",
        "              ax.set_axis_off()\n",
        "            elif i == 2: # in [2, 6, 10, 14]: # [2, 6, 10, 14, 18, 22, 26, 30]:\n",
        "              ax.imshow(preds[batch].cpu().round())\n",
        "              ax.set_title(\"Preds\")\n",
        "              ax.set_axis_off()\n",
        "            else:\n",
        "              ax.imshow(label[batch][0].cpu())\n",
        "              ax.set_title(\"Label\")\n",
        "              ax.set_axis_off()\n",
        "\n",
        "          # if batch == 3 or batch == 7:\n",
        "          plt.savefig(f'/content/gdrive/My Drive/Validation_imgs/pic_{n_elem}.png')\n",
        "          plt.close()\n",
        "\n",
        "        del axes\n",
        "\n",
        "        all_labels = np.concatenate((all_labels, label.flatten().cpu().int()))\n",
        "        all_preds = np.concatenate((all_preds, preds.flatten().cpu().int()))\n",
        "        del img1, img2, label\n",
        "\n",
        "    # print(f\"TP = {tp}, TN = {tn}, FP = {fp}, FN = {fn}\")\n",
        "\n",
        "    val_loss = np.array(epoch_loss).mean()\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "    del all_labels, all_preds\n",
        "\n",
        "    return val_loss, accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vz72pGlRoj5",
        "outputId": "79a68fb4-7bf4-4c68-bdb2-25c21586bb25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded. Resuming training from Epoch 8 with:\n",
            "Train loss = 0.4073, Accuracy: 0.5777 | Validation loss = 0.3646, Accuracy = 0.4519, Precision = 0.0038, Recall = 0.5928, F1_score = 0.0075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [32:45<00:00, 14.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30, Training Loss: 0.3937, Accuracy: 0.5755\n",
            "Saving training stats for epoch 9...\n",
            "Training stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [03:42<00:00, 14.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: Loss = 0.3575, Accuracy = 0.3970, Precision: 0.0031, Recall: 0.5467, F1-score: 0.0063\n",
            "Saving validation stats for epoch 9...\n",
            "Validation stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135/135 [32:53<00:00, 14.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30, Training Loss: 0.3828, Accuracy: 0.5691\n",
            "Saving training stats for epoch 10...\n",
            "Training stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [03:51<00:00, 15.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: Loss = 0.3394, Accuracy = 0.3932, Precision: 0.0035, Recall: 0.6172, F1-score: 0.0070\n",
            "Saving validation stats for epoch 10...\n",
            "Validation stats saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 114/135 [28:26<05:49, 16.63s/it]"
          ]
        }
      ],
      "source": [
        "restart_epoch = 0\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "# checkpoint_path = f'/content/gdrive/My Drive/Colab_Notebooks/checkpoint/checkpoint_DENUNET_epoch_7.pt'\n",
        "checkpoint_path = f'/content/gdrive/My Drive/Colab_Notebooks/checkpoint/checkpoint_SIAMNET_epoch_8.pt'\n",
        "# checkpoint_path = f'/content/gdrive/My Drive/Colab_Notebooks/checkpoint/checkpoint_UNET_epoch_15.pt'\n",
        "\n",
        "# Carica il checkpoint se esiste\n",
        "if os.path.exists(checkpoint_path):\n",
        "  checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  restart_epoch = checkpoint['epoch'] + 1 # Riprende dalla prossima epoca\n",
        "  train_loss = checkpoint['loss']\n",
        "  train_acc = checkpoint['train accuracy']\n",
        "  val_loss = checkpoint['validation loss']\n",
        "  accuracy = checkpoint['accuracy']\n",
        "  precision = checkpoint['precision']\n",
        "  recall = checkpoint['recall']\n",
        "  f1 = checkpoint['f1_score']\n",
        "  print(f\"Checkpoint loaded. Resuming training from Epoch {restart_epoch} with:\")\n",
        "  print(f\"Train loss = {train_loss:.4f}, Accuracy: {train_acc:.4f} | Validation loss = {val_loss:.4f}, Accuracy = {accuracy:.4f}, Precision = {precision:.4f}, Recall = {recall:.4f}, F1_score = {f1:.4f}\")\n",
        "else:\n",
        "  print(f\"Checkpoint not found! Training from zero...\")\n",
        "\n",
        "for epoch in range(restart_epoch, NUM_EPOCHS):\n",
        "\n",
        "  val_loss, accuracy, precision, recall, f1 = 0.0, 0.0, 0.0, 0.0, 0.0\n",
        "\n",
        "  train_loss, train_acc = train()\n",
        "  print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Training Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "  print(f\"Saving training stats for epoch {epoch+1}...\")\n",
        "  checkpoint = {\n",
        "      'epoch': epoch,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'loss': train_loss,\n",
        "      'train accuracy': train_acc,\n",
        "      'validation loss': val_loss,\n",
        "      'accuracy' : accuracy,\n",
        "      'precision' : precision,\n",
        "      'recall' : recall,\n",
        "      'f1_score' : f1\n",
        "  }\n",
        "  torch.save(checkpoint, f'/content/gdrive/My Drive/Colab_Notebooks/checkpoint/checkpoint_SIAMNET_epoch_{epoch+1}.pt')\n",
        "  print(\"Training stats saved!\")\n",
        "\n",
        "  val_loss, accuracy, precision, recall, f1 = validate()\n",
        "  print(f\"Validation: Loss = {val_loss:.4f}, Accuracy = {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "  # Salvataggio del checkpoint dopo ogni epoca\n",
        "  print(f\"Saving validation stats for epoch {epoch+1}...\")\n",
        "  checkpoint = {\n",
        "      'epoch': epoch,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'loss': train_loss,\n",
        "      'train accuracy': train_acc,\n",
        "      'validation loss': val_loss,\n",
        "      'accuracy' : accuracy,\n",
        "      'precision' : precision,\n",
        "      'recall' : recall,\n",
        "      'f1_score' : f1\n",
        "  }\n",
        "  torch.save(checkpoint, f'/content/gdrive/My Drive/Colab_Notebooks/checkpoint/checkpoint_SIAMNET_epoch_{epoch+1}.pt')\n",
        "  # torch.save(checkpoint, f'/content/gdrive/My Drive/Colab_Notebooks/checkpoint/checkpoint_UNET_epoch_{epoch+1}.pt')\n",
        "  # torch.save(checkpoint, f'/content/gdrive/My Drive/Colab_Notebooks/checkpoint/checkpoint_DENUNET_epoch_{epoch+1}.pt')\n",
        "  print(\"Validation stats saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for epoch in range(19):\n",
        "  checkpoint_path = f'/content/gdrive/My Drive/Colab_Notebooks/checkpoint/lr=0.00001/checkpoint_UNET_epoch_{epoch+1}.pt'\n",
        "\n",
        "  # Carica il checkpoint se esiste\n",
        "  if os.path.exists(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
        "    # model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    # restart_epoch = checkpoint['epoch'] + 1 # Riprende dalla prossima epoca\n",
        "    train_loss = checkpoint['loss']\n",
        "    train_acc = checkpoint['train accuracy']\n",
        "    val_loss = checkpoint['validation loss']\n",
        "    accuracy = checkpoint['accuracy']\n",
        "    precision = checkpoint['precision']\n",
        "    recall = checkpoint['recall']\n",
        "    f1 = checkpoint['f1_score']\n",
        "    print(f\"Train loss = {train_loss:.4f}, Accuracy: {train_acc:.4f} | Validation loss = {val_loss:.4f}, Accuracy = {accuracy:.4f}, Precision = {precision:.4f}, Recall = {recall:.4f}, F1_score = {f1:.4f}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aVPCCFyVqudh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for epoch in range(28):\n",
        "  checkpoint_path = f'/content/gdrive/My Drive/Colab_Notebooks/checkpoint/lr=0.00001/checkpoint_SIAMNET_epoch_{epoch+1}.pt'\n",
        "\n",
        "  # Carica il checkpoint se esiste\n",
        "  if os.path.exists(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
        "    # model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    # restart_epoch = checkpoint['epoch'] + 1 # Riprende dalla prossima epoca\n",
        "    train_loss = checkpoint['loss']\n",
        "    train_acc = checkpoint['train accuracy']\n",
        "    val_loss = checkpoint['validation loss']\n",
        "    accuracy = checkpoint['accuracy']\n",
        "    precision = checkpoint['precision']\n",
        "    recall = checkpoint['recall']\n",
        "    f1 = checkpoint['f1_score']\n",
        "    print(f\"Train loss = {train_loss:.4f}, Accuracy: {train_acc:.4f} | Validation loss = {val_loss:.4f}, Accuracy = {accuracy:.4f}, Precision = {precision:.4f}, Recall = {recall:.4f}, F1_score = {f1:.4f}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tJoaXZ9EsTCG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "M1xTt21vEOR4",
        "upApRwj5A0Hr",
        "GyUNkYKy5bFd"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}